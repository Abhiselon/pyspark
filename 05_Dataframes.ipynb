{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a73ee05c-f04a-4129-a08f-324cd77be2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "844ad421-4b3a-4ef4-9256-3d95fcd50e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"Dataframe\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38bc67a-980f-4265-8f88-2676068b060d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Using RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1adc4447-db31-405d-8dbc-4b4f7c5f4848",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.textFile(\"data/input_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5c7d2e9-b734-4d1b-b008-4cc87c1f8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rdd = rdd.flatMap(lambda line:line.split(\" \")).map(lambda word: (word,1)).reduceByKey(lambda a,b: a + b).sortBy(lambda x: x[1],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f64a4b5-0eed-4799-aa9c-a51c36233c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 7),\n",
       " ('the', 7),\n",
       " ('for', 6),\n",
       " ('of', 5),\n",
       " ('a', 5),\n",
       " ('data', 5),\n",
       " ('faster', 4),\n",
       " ('', 4),\n",
       " ('dataset', 4),\n",
       " ('Spark', 4),\n",
       " ('in', 4),\n",
       " ('on', 4),\n",
       " ('also', 4),\n",
       " ('reviews', 4),\n",
       " ('to', 3),\n",
       " ('as', 3),\n",
       " ('around', 3),\n",
       " ('or', 3),\n",
       " ('Dataset:', 3),\n",
       " ('contains', 3),\n",
       " ('The', 3),\n",
       " ('includes', 3),\n",
       " ('more', 2),\n",
       " ('you', 2),\n",
       " ('it', 2),\n",
       " ('have', 2),\n",
       " ('at', 2),\n",
       " ('Review', 2),\n",
       " ('hotel', 2),\n",
       " ('car', 2),\n",
       " ('25,000', 2),\n",
       " ('Twitter', 2),\n",
       " ('over', 2),\n",
       " ('one', 2),\n",
       " ('This', 2),\n",
       " ('which', 2),\n",
       " ('tweets', 2),\n",
       " ('general', 1),\n",
       " ('lets', 1),\n",
       " ('up', 1),\n",
       " ('100x', 1),\n",
       " ('memory,', 1),\n",
       " ('disk,', 1),\n",
       " ('than', 1),\n",
       " ('Last', 1),\n",
       " ('took', 1),\n",
       " ('Hadoop', 1),\n",
       " ('by', 1),\n",
       " ('completing', 1),\n",
       " ('TB', 1),\n",
       " ('Daytona', 1),\n",
       " ('contest', 1),\n",
       " ('3x', 1),\n",
       " ('tenth', 1),\n",
       " ('number', 1),\n",
       " ('machines', 1),\n",
       " ('write', 1),\n",
       " ('80', 1),\n",
       " ('To', 1),\n",
       " ('demonstrate', 1),\n",
       " ('this,', 1),\n",
       " ('let’s', 1),\n",
       " ('“Hello', 1),\n",
       " ('World!”', 1),\n",
       " ('Word', 1),\n",
       " ('Count', 1),\n",
       " ('example.', 1),\n",
       " ('reviews:', 1),\n",
       " ('TripAdvisor,', 1),\n",
       " ('another', 1),\n",
       " ('TripAdvisor', 1),\n",
       " ('10', 1),\n",
       " ('world,', 1),\n",
       " ('hotels', 1),\n",
       " ('city.', 1),\n",
       " ('Edmunds', 1),\n",
       " ('review', 1),\n",
       " ('covers', 1),\n",
       " ('2009,', 1),\n",
       " ('full', 1),\n",
       " ('reviews.', 1),\n",
       " ('Large', 1),\n",
       " ('By', 1),\n",
       " ('AI', 1),\n",
       " ('Laboratory,', 1),\n",
       " ('this', 1),\n",
       " ('text', 1),\n",
       " ('classification', 1),\n",
       " ('set', 1),\n",
       " ('highly', 1),\n",
       " ('polar', 1),\n",
       " ('with', 1),\n",
       " ('an', 1),\n",
       " ('training.', 1),\n",
       " ('useful', 1),\n",
       " ('analysis', 1),\n",
       " ('It', 1),\n",
       " ('unlabeled', 1),\n",
       " ('used', 1),\n",
       " ('further', 1),\n",
       " ('Airline', 1),\n",
       " ('contributors', 1),\n",
       " ('positive,', 1),\n",
       " ('neutral.', 1),\n",
       " ('reasons', 1),\n",
       " ('were', 1),\n",
       " ('under', 1),\n",
       " ('titles', 1),\n",
       " ('such', 1),\n",
       " ('are', 1),\n",
       " ('six', 1),\n",
       " ('provides', 1),\n",
       " ('processing', 1),\n",
       " ('platform.', 1),\n",
       " ('run', 1),\n",
       " ('programs', 1),\n",
       " ('10x', 1),\n",
       " ('Hadoop.', 1),\n",
       " ('year,', 1),\n",
       " ('100', 1),\n",
       " ('GraySort', 1),\n",
       " ('became', 1),\n",
       " ('fastest', 1),\n",
       " ('open', 1),\n",
       " ('source', 1),\n",
       " ('engine', 1),\n",
       " ('sorting', 1),\n",
       " ('petabyte.', 1),\n",
       " ('makes', 1),\n",
       " ('possible', 1),\n",
       " ('code', 1),\n",
       " ('quickly', 1),\n",
       " ('high-level', 1),\n",
       " ('operators', 1),\n",
       " ('your', 1),\n",
       " ('disposal.', 1),\n",
       " ('look', 1),\n",
       " ('BigData:', 1),\n",
       " ('Opin-Rank', 1),\n",
       " ('two', 1),\n",
       " ('sets', 1),\n",
       " ('Edmunds.', 1),\n",
       " ('259,000', 1),\n",
       " ('cities', 1),\n",
       " ('80-700', 1),\n",
       " ('each', 1),\n",
       " ('2007', 1),\n",
       " ('dates,', 1),\n",
       " ('author', 1),\n",
       " ('names,', 1),\n",
       " ('textual', 1),\n",
       " ('Movie', 1),\n",
       " ('Stanford', 1),\n",
       " ('movie', 1),\n",
       " ('reviews,', 1),\n",
       " ('additional', 1),\n",
       " ('is', 1),\n",
       " ('sentiment', 1),\n",
       " ('experiments.', 1),\n",
       " ('can', 1),\n",
       " ('be', 1),\n",
       " ('training', 1),\n",
       " ('testing.', 1),\n",
       " ('US', 1),\n",
       " ('Sentiment', 1),\n",
       " ('collection', 1),\n",
       " ('classified', 1),\n",
       " ('negative,', 1),\n",
       " ('Negative', 1),\n",
       " ('categorized', 1),\n",
       " ('“late', 1),\n",
       " ('flight”', 1),\n",
       " ('“rude', 1),\n",
       " ('service”.', 1),\n",
       " ('In', 1),\n",
       " ('total', 1),\n",
       " ('there', 1),\n",
       " ('15,000', 1),\n",
       " ('across', 1),\n",
       " ('airlines.', 1)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784c484b-804e-4d39-a96c-6aa4e2ca88d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01fa3629-bb96-4c1c-83d3-29ae2d94d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b122e74-37f6-4b7d-b314-27baf3f247e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.text(\"data/input_data.txt\")\n",
    "\n",
    "result_df = df.selectExpr(\"explode(split(value, ' ')) as word\").groupBy(\"word\").count().orderBy(desc(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eb78290f-5660-4be8-a884-8e044387b746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(word='the', count=7),\n",
       " Row(word='and', count=7),\n",
       " Row(word='for', count=6),\n",
       " Row(word='data', count=5),\n",
       " Row(word='of', count=5),\n",
       " Row(word='a', count=5),\n",
       " Row(word='on', count=4),\n",
       " Row(word='Spark', count=4),\n",
       " Row(word='dataset', count=4),\n",
       " Row(word='in', count=4)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a8c93347-699e-4eb9-86b9-80801eea8d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|    word|count|\n",
      "+--------+-----+\n",
      "|     the|    7|\n",
      "|     and|    7|\n",
      "|     for|    6|\n",
      "|    data|    5|\n",
      "|      of|    5|\n",
      "|       a|    5|\n",
      "|      in|    4|\n",
      "|      on|    4|\n",
      "| dataset|    4|\n",
      "|   Spark|    4|\n",
      "|  faster|    4|\n",
      "|        |    4|\n",
      "| reviews|    4|\n",
      "|    also|    4|\n",
      "|contains|    3|\n",
      "|includes|    3|\n",
      "|Dataset:|    3|\n",
      "|  around|    3|\n",
      "|     The|    3|\n",
      "|      as|    3|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd981aea-46e6-4f5e-9abe-99045e4d7358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index,Customer Id,First Name,Last Name,Company,City,Country,Phone 1,Phone 2,Email,Subscription Date,Website\n",
      "1,DD37Cf93aecA6Dc,Sheryl,Baxter,Rasmussen Group,East Leonard,Chile,229.077.5154,397.884.0519x718,zunigavanessa@smith.info,2020-08-24,http://www.stephenson.com/\n",
      "2,1Ef7b82A4CAAD10,Preston,Lozano,Vega-Gentry,East Jimmychester,Djibouti,5153435776,686-620-1820x944,vmata@colon.com,2021-04-23,http://www.hobbs.com/\n",
      "3,6F94879bDAfE5a6,Roy,Berry,Murillo-Perry,Isabelborough,Antigua and Barbuda,+1-539-402-0259,(496)978-3969x58947,beckycarr@hogan.com,2020-03-25,http://www.lawrence.com/\n",
      "4,5Cef8BFA16c5e3c,Linda,Olsen,\"Dominguez, Mcmillan and Donovan\",Bensonview,Dominican Republic,001-808-617-6467x12895,+1-813-324-8756,stanleyblackwell@benson.org,2020-06-02,http://www.good-lyons.com/\n",
      "5,053d585Ab6b3159,Joanna,Bender,\"Martin, Lang and Andrade\",West Priscilla,Slovakia (Slovak Republic),001-234-203-0635x76146,001-199-446-3860x3486,colinalvarado@miles.net,2021-04-17,https://goodwin-ingram.com/\n",
      "6,2d08FB17EE273F4,Aimee,Downs,Steele Group,Chavezborough,Bosnia and Herzegovina,(283)437-3886x88321,999-728-1637,louis27@gilbert.com,2020-02-25,http://www.berger.net/\n",
      "7,EA4d384DfDbBf77,Darren,Peck,\"Lester, Woodard and Mitchell\",Lake Ana,Pitcairn Islands,(496)452-6181x3291,+1-247-266-0963x4995,tgates@cantrell.com,2021-08-24,https://www.le.com/\n",
      "8,0e04AFde9f225dE,Brett,Mullen,\"Sanford, Davenport and Giles\",Kimport,Bulgaria,001-583-352-7197x297,001-333-145-0369,asnow@colon.com,2021-04-12,https://hammond-ramsey.com/\n",
      "9,C2dE4dEEc489ae0,Sheryl,Meyers,Browning-Simon,Robersonstad,Cyprus,854-138-4911x5772,+1-448-910-2276x729,mariokhan@ryan-pope.org,2020-01-13,https://www.bullock.net/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head -10 ./data/customers.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b0572-7356-4460-8349-5bedcc25950f",
   "metadata": {},
   "source": [
    "## Read CSV with header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52a505a3-a552-4cdd-aa6e-21ed861e4f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into DataFrame\n",
    "cust_df = spark.read.csv(\"data/customers.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3c548ca-952d-4989-bed1-f10651267cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Index: string (nullable = true)\n",
      " |-- Customer Id: string (nullable = true)\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- Last Name: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Phone 1: string (nullable = true)\n",
      " |-- Phone 2: string (nullable = true)\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Subscription Date: string (nullable = true)\n",
      " |-- Website: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display schema of DataFrame\n",
    "cust_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d73f39e-da0e-4202-b245-7c959e45e54f",
   "metadata": {},
   "source": [
    "## Read CSV with an explicit schema definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8324672-fe77-43ac-b419-65f8bc977572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary types\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ab31811-4644-41b8-b705-3c10d76c043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(name=\"Index\", dataType=IntegerType(), nullable=True),\n",
    "    StructField(name=\"Customer Id\", dataType=StringType(), nullable=True),\n",
    "    StructField(name=\"First Name\", dataType=StringType(), nullable=True),\n",
    "    StructField(name=\"Last Name\", dataType=StringType(), nullable=True),\n",
    "    StructField(name=\"Company\", dataType=StringType(), nullable=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5166ea2-3941-46c4-bf5f-ed524f43e993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into DataFrame with schema definition\n",
    "csv_file_path = \"./data/customers.csv\"\n",
    "df = spark.read.csv(csv_file_path, header=True,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd8b7f06-480e-4c04-93fa-077c05db437f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Index: integer (nullable = true)\n",
      " |-- Customer Id: string (nullable = true)\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- Last Name: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      "\n",
      "+-----+---------------+----------+---------+--------------------+\n",
      "|Index|    Customer Id|First Name|Last Name|             Company|\n",
      "+-----+---------------+----------+---------+--------------------+\n",
      "|    1|DD37Cf93aecA6Dc|    Sheryl|   Baxter|     Rasmussen Group|\n",
      "|    2|1Ef7b82A4CAAD10|   Preston|   Lozano|         Vega-Gentry|\n",
      "|    3|6F94879bDAfE5a6|       Roy|    Berry|       Murillo-Perry|\n",
      "|    4|5Cef8BFA16c5e3c|     Linda|    Olsen|Dominguez, Mcmill...|\n",
      "|    5|053d585Ab6b3159|    Joanna|   Bender|Martin, Lang and ...|\n",
      "+-----+---------------+----------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display schema of DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "# Display content of DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200a0ef9-8701-4415-8397-6e69b227c377",
   "metadata": {},
   "source": [
    "## Read CSV with inferSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16284340-90ed-4d95-8d9a-129b23b63873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into DataFrame with inferSchema\n",
    "csv_file_path = \"./data/customers.csv\"\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f163a2ed-aa32-4345-a0ba-e8f54a966f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Index: integer (nullable = true)\n",
      " |-- Customer Id: string (nullable = true)\n",
      " |-- First Name: string (nullable = true)\n",
      " |-- Last Name: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Phone 1: string (nullable = true)\n",
      " |-- Phone 2: string (nullable = true)\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Subscription Date: date (nullable = true)\n",
      " |-- Website: string (nullable = true)\n",
      "\n",
      "+-----+---------------+----------+---------+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "|Index|    Customer Id|First Name|Last Name|             Company|             City|             Country|             Phone 1|             Phone 2|               Email|Subscription Date|             Website|\n",
      "+-----+---------------+----------+---------+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "|    1|DD37Cf93aecA6Dc|    Sheryl|   Baxter|     Rasmussen Group|     East Leonard|               Chile|        229.077.5154|    397.884.0519x718|zunigavanessa@smi...|       2020-08-24|http://www.stephe...|\n",
      "|    2|1Ef7b82A4CAAD10|   Preston|   Lozano|         Vega-Gentry|East Jimmychester|            Djibouti|          5153435776|    686-620-1820x944|     vmata@colon.com|       2021-04-23|http://www.hobbs....|\n",
      "|    3|6F94879bDAfE5a6|       Roy|    Berry|       Murillo-Perry|    Isabelborough| Antigua and Barbuda|     +1-539-402-0259| (496)978-3969x58947| beckycarr@hogan.com|       2020-03-25|http://www.lawren...|\n",
      "|    4|5Cef8BFA16c5e3c|     Linda|    Olsen|Dominguez, Mcmill...|       Bensonview|  Dominican Republic|001-808-617-6467x...|     +1-813-324-8756|stanleyblackwell@...|       2020-06-02|http://www.good-l...|\n",
      "|    5|053d585Ab6b3159|    Joanna|   Bender|Martin, Lang and ...|   West Priscilla|Slovakia (Slovak ...|001-234-203-0635x...|001-199-446-3860x...|colinalvarado@mil...|       2021-04-17|https://goodwin-i...|\n",
      "+-----+---------------+----------+---------+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display schema of DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "# Display content of DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beaa5bd-d0ce-44e4-9249-1d4382cc4a7c",
   "metadata": {},
   "source": [
    "## Read JSON file into DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9490cdc-9a37-449a-b4f0-35e14fe4b130",
   "metadata": {},
   "source": [
    "### Single Line JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d04f85b7-f071-44ed-8ef7-f31e7a75ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read single line JSON\n",
    "# Each row is a JSON record, records are separated by new line\n",
    "json_file_path = \"./data/products_singleline.json\"\n",
    "df = spark.read.json(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35001b98-defd-4e27-b7ab-2113b7f7759e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- quantity: long (nullable = true)\n",
      "\n",
      "+---------------+---+--------------------+------+--------+\n",
      "|       category| id|                name| price|quantity|\n",
      "+---------------+---+--------------------+------+--------+\n",
      "|    Electronics|  1|           iPhone 12|899.99|      10|\n",
      "|       Clothing|  2|     Nike Air Max 90|119.99|      25|\n",
      "|Home Appliances|  3|KitchenAid Stand ...|299.99|       5|\n",
      "|          Books|  4|    The Great Gatsby| 12.99|      50|\n",
      "|         Beauty|  5|L'Oreal Paris Mas...|  9.99|     100|\n",
      "+---------------+---+--------------------+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display schema of DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "# Display content of DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c937bfc7-984d-4821-9d81-19689263b2de",
   "metadata": {},
   "source": [
    "### Multi-lines JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8edc00d-a665-4463-9d17-4445da17c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read multi-line JSON\n",
    "# JSON is an array of record, records are separated by a comma.\n",
    "# each record is defined in multiple lines\n",
    "json_file_path = \"./data/products_multiline.json\"\n",
    "df = spark.read.json(json_file_path, multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "876b9f56-5d86-4399-a036-3d9c84c3aeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- quantity: long (nullable = true)\n",
      "\n",
      "+---------------+---+--------------------+------+--------+\n",
      "|       category| id|                name| price|quantity|\n",
      "+---------------+---+--------------------+------+--------+\n",
      "|    Electronics|  1|           iPhone 12|899.99|      10|\n",
      "|       Clothing|  2|     Nike Air Max 90|119.99|      25|\n",
      "|Home Appliances|  3|KitchenAid Stand ...|299.99|       5|\n",
      "|          Books|  4|    The Great Gatsby| 12.99|      50|\n",
      "|         Beauty|  5|L'Oreal Paris Mas...|  9.99|     100|\n",
      "+---------------+---+--------------------+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display schema of DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "# Display content of DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb7bed9c-5dab-4e0c-a51e-7f6911213caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe into parquet file\n",
    "parquet_file_path = \"./data/products.parquet\"\n",
    "df.write.mode('overwrite').partitionBy('category').parquet(parquet_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8daecd1-7c8e-48fe-9eb7-12148d2d34a0",
   "metadata": {},
   "source": [
    "### Read parquet file into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1843297e-803d-46f8-8ef8-b9fb0e13fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(parquet_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b9f35ef-34ee-4aac-9462-5a276590ffc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- quantity: long (nullable = true)\n",
      "\n",
      "+---------------+---+--------------------+------+--------+\n",
      "|       category| id|                name| price|quantity|\n",
      "+---------------+---+--------------------+------+--------+\n",
      "|    Electronics|  1|           iPhone 12|899.99|      10|\n",
      "|       Clothing|  2|     Nike Air Max 90|119.99|      25|\n",
      "|Home Appliances|  3|KitchenAid Stand ...|299.99|       5|\n",
      "|          Books|  4|    The Great Gatsby| 12.99|      50|\n",
      "|         Beauty|  5|L'Oreal Paris Mas...|  9.99|     100|\n",
      "+---------------+---+--------------------+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display schema of DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "# Display content of DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55309bd0-7e3a-48d5-bc63-7aaec1c8cedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-O64RPERE.bbrouter:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x21b95769cd0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6c0f766a-13bb-4ca1-ae5f-fabe08ed62c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark1 = SparkSession.builder \\\n",
    "    .enableHiveSupport() \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"C:/spark-warehouse\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "35d3c19b-e302-48b5-8fd2-ce42472348ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"./data/customers.csv\"\n",
    "df = spark1.read.csv(csv_file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "de09535a-4ab2-4f9e-810a-7b0ceb6a31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write \\\n",
    "    .bucketBy(5, \"Index\") \\\n",
    "    .sortBy(\"Index\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"mytable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d4b41f20-7380-44cb-9f09-5e920fae0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = spark1.sql(\"SELECT `First Name`, Company FROM mytable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "212d0e83-159f-4ea5-a799-3af6a9163e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|First Name|             Company|\n",
      "+----------+--------------------+\n",
      "|   Preston|         Vega-Gentry|\n",
      "|     Aimee|        Steele Group|\n",
      "|    Sheryl|      Browning-Simon|\n",
      "|     Jenna|Hoffman, Reed and...|\n",
      "|   Miranda|  Singleton and Sons|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_read.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cc7841f7-6c33-4928-a263-a6205f785f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark1.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
